{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three data sets are required for each environment \n",
    "* __Expert dataset (D1)__ (generated by an agent that solves the environment)\n",
    "* __Suboptimal dataset (D2)__ (generated by an agent showing suboptimal results)\n",
    "* __Random dataset (D3)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.gail import generate_expert_traj\n",
    "from BEAR.utils import ReplayBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting a expert off-policy dataset\n",
    "Erkl√§rung hier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0507 11:04:50.742345 140550023841600 deprecation_wrapper.py:119] From /home/uvegz/envs/venv_mujoco/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0507 11:04:50.742906 140550023841600 deprecation_wrapper.py:119] From /home/uvegz/envs/venv_mujoco/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0507 11:04:50.748330 140550023841600 deprecation_wrapper.py:119] From /home/uvegz/envs/venv_mujoco/lib/python3.6/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0507 11:04:50.749042 140550023841600 deprecation_wrapper.py:119] From /home/uvegz/envs/venv_mujoco/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0507 11:04:50.750158 140550023841600 deprecation.py:323] From /home/uvegz/envs/venv_mujoco/lib/python3.6/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0507 11:04:50.908054 140550023841600 deprecation_wrapper.py:119] From /home/uvegz/envs/venv_mujoco/lib/python3.6/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:./data/expert_traj/Pendulum-v0_expert_1E02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0507 11:04:51.031216 140550023841600 deprecation_wrapper.py:119] From /home/uvegz/envs/venv_mujoco/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0507 11:04:51.047035 140550023841600 deprecation.py:323] From /home/uvegz/envs/venv_mujoco/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0507 11:04:51.188100 140550023841600 deprecation_wrapper.py:119] From /home/uvegz/envs/venv_mujoco/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0507 11:04:51.303235 140550023841600 deprecation_wrapper.py:119] From /home/uvegz/envs/venv_mujoco/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions (20000, 1)\n",
      "obs (20000, 3)\n",
      "rewards (20000, 1)\n",
      "episode_returns (100,)\n",
      "episode_starts (20000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'actions': array([[ 2.6707017e-01],\n",
       "        [ 2.4451163e-01],\n",
       "        [ 5.8600211e-01],\n",
       "        ...,\n",
       "        [-1.1299404e+00],\n",
       "        [-3.3715737e-01],\n",
       "        [-1.0659453e-03]], dtype=float32),\n",
       " 'obs': array([[-0.5745079 , -0.818499  , -0.5039217 ],\n",
       "        [-0.6177589 , -0.78636754, -1.0777354 ],\n",
       "        [-0.679757  , -0.73343736, -1.6308343 ],\n",
       "        ...,\n",
       "        [-0.85701793,  0.5152866 , -3.384071  ],\n",
       "        [-0.7650374 ,  0.6439858 , -3.167097  ],\n",
       "        [-0.67011625,  0.74225616, -2.7346814 ]], dtype=float32),\n",
       " 'rewards': array([[-4.790077],\n",
       "        [-5.118975],\n",
       "        [-5.640485],\n",
       "        ...,\n",
       "        [-7.907774],\n",
       "        [-6.966019],\n",
       "        [-6.061619]], dtype=float32),\n",
       " 'episode_returns': array([-1400.61669922, -1166.52453613, -1032.36010742, -1119.93310547,\n",
       "        -1565.24047852,  -805.77789307, -1072.70117188, -1702.51831055,\n",
       "        -1281.86682129, -1285.95861816, -1164.44848633, -1324.03234863,\n",
       "         -874.5345459 , -1055.77038574,  -881.9609375 ,  -917.78863525,\n",
       "        -1783.18566895, -1570.81750488, -1418.04760742, -1012.49920654,\n",
       "         -852.05651855, -1246.40734863, -1173.16491699, -1296.36328125,\n",
       "        -1149.2166748 , -1190.18920898, -1323.20544434,  -981.87121582,\n",
       "        -1279.25744629, -1324.64685059, -1164.68811035, -1461.78637695,\n",
       "         -953.90808105,  -962.61834717, -1485.59301758,  -865.55480957,\n",
       "        -1073.21948242, -1390.24035645, -1491.75708008,  -927.51605225,\n",
       "        -1292.12341309, -1358.89550781, -1250.14416504, -1158.45471191,\n",
       "        -1178.36071777,  -756.06726074, -1292.39440918, -1406.73425293,\n",
       "        -1656.68945312, -1631.25952148, -1085.37475586,  -888.19525146,\n",
       "         -877.73284912, -1386.28894043,  -958.48815918, -1180.33044434,\n",
       "        -1702.57678223, -1086.19616699, -1179.16894531,  -782.89471436,\n",
       "         -904.71881104,  -969.40496826, -1572.92175293, -1613.78344727,\n",
       "        -1581.96435547, -1419.7824707 , -1770.25952148, -1044.06481934,\n",
       "        -1292.47473145,  -726.57824707, -1600.40197754,  -957.60375977,\n",
       "        -1434.48425293,  -959.01678467,  -761.73297119, -1834.13366699,\n",
       "        -1073.24060059,  -856.08935547, -1437.79797363, -1232.91723633,\n",
       "         -864.31256104, -1444.22802734,  -921.65948486,  -965.9407959 ,\n",
       "        -1017.97302246,  -847.87768555, -1211.75354004, -1338.17712402,\n",
       "        -1065.91040039, -1275.77941895,  -967.50305176, -1078.39709473,\n",
       "        -1290.71142578, -1655.74658203,  -884.51220703,  -895.91125488,\n",
       "         -871.35394287,  -634.09472656,  -877.43310547, -1323.91101074]),\n",
       " 'episode_starts': array([True, array([False]), array([False]), ..., array([False]),\n",
       "        array([False]), array([False])], dtype=object)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Parameters\n",
    "dataste_n_episodes = 1e2 # number of episodes in the dataset \n",
    "train_n_steps = 1e2 # number of tranings steps befor collecting data \n",
    "env_name = 'Pendulum-v0' # name of the enviornment\n",
    "\n",
    "# Set path\n",
    "steps_str = ('%.E' % train_n_steps).replace(\"+\",\"\") \n",
    "dataset_name = env_name+'_expert_'+steps_str # name of the dataset\n",
    "dir_name = \"./data/expert_traj/\" # path to the directory\n",
    "path = os.path.join(dir_name, dataset_name)\n",
    "\n",
    "# make sure the directory exists\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "\n",
    "print('path:' + path + '\\n')\n",
    "    \n",
    "# Set Parameters\n",
    "dataste_n_episodes = 1e2 # number of episodes in the dataset \n",
    "train_n_steps = 1e2 # number of tranings steps befor collecting data \n",
    "\n",
    "# Collect dataset\n",
    "model = PPO2('MlpPolicy', env_name, verbose=0)\n",
    "generate_expert_traj(model, path, n_timesteps=int(train_n_steps), n_episodes=int(dataste_n_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform a NPZ in a ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/expert_traj/Pendulum-v0_expert_1E02.npz\n"
     ]
    }
   ],
   "source": [
    "# set path to NPZ file\n",
    "load_path = os.path.normpath('./data/expert_traj/Pendulum-v0_expert_1E02.npz')\n",
    "print(load_path)\n",
    "\n",
    "# Set path\n",
    "dataset_name = (load_path.split('/')[-1]).split('.')[0]\n",
    "dir_name = \"./data/buffers/\" # path to the directory\n",
    "save_path = os.path.join(dir_name, dataset_name)\n",
    "\n",
    "# make sure the directory exists\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "\n",
    "# load data\n",
    "data = np.load(load_path, allow_pickle=True)\n",
    "obs = data['obs'] # shape = (878987, 4)\n",
    "actions = data['actions'] # shape = (878987, 1)\n",
    "rewards = data['rewards'] # shape = (878987, )\n",
    "episode_starts = data['episode_starts']\n",
    "\n",
    "# set ReplayBuffer\n",
    "obs_dim = obs.shape[1]\n",
    "actions_dim = actions.shape[1]\n",
    "size = actions.shape[0]\n",
    "replay_buffer = ReplayBuffer(obs_dim, actions_dim, size)\n",
    "\n",
    "# Transform to ReplayBuffer\n",
    "for i in range(len(obs)-2):\n",
    "    if episode_starts[i+1]!=True:\n",
    "        state = obs[i]\n",
    "        next_state = obs[i+1]\n",
    "        action = actions[i]\n",
    "        reward = rewards[i]\n",
    "        if episode_starts[i+2]!=True:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "    data = (state, next_state, action, reward, done)\n",
    "    replay_buffer.add(data)\n",
    "    \n",
    "# save ReplayBuffer    \n",
    "replay_buffer.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9904904 ,  0.13758214,  1.6978359 ],\n",
       "       [ 0.6968495 ,  0.7172174 , -1.7568618 ],\n",
       "       [ 0.33129063, -0.9435288 , -1.9987622 ],\n",
       "       [-0.5448447 , -0.838537  ,  2.7617214 ],\n",
       "       [ 0.15353766,  0.9881428 ,  4.9368424 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, s2, a, r, d, mask = replay_buffer.sample(5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.12015381, -0.9927553 , -3.477377  ],\n",
       "        [-0.9777932 , -0.20957206, -6.9724307 ]], dtype=float32),\n",
       " array([[-0.31934118, -0.9476398 , -4.0917873 ],\n",
       "        [-0.99076784,  0.1355695 , -6.9425106 ]], dtype=float32),\n",
       " array([[0.8677073],\n",
       "        [1.2473264]], dtype=float32),\n",
       " array([[ -4.0702643],\n",
       "        [-13.4506035]], dtype=float32),\n",
       " array([[1.],\n",
       "        [1.]], dtype=float32),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
