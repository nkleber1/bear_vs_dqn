{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three data sets are required for each environment \n",
    "* Expert dataset (generated by an agent that solves the environment)\n",
    "* Suboptimal dataset (generated by an agent that solves the environment)\n",
    "* Random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines.gail import generate_expert_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting a expert off-policy dataset\n",
    "Erkl√§rung hier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating environment from the given name, wrapped in a DummyVecEnv.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 98       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 20.4     |\n",
      "| steps                   | 2022     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 22.3     |\n",
      "| steps                   | 4248     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 24.2     |\n",
      "| steps                   | 6673     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 91       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 23.6     |\n",
      "| steps                   | 9028     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 88       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 22.2     |\n",
      "| steps                   | 11247    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 23.4     |\n",
      "| steps                   | 13589    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 84       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 23.9     |\n",
      "| steps                   | 15979    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 23.3     |\n",
      "| steps                   | 18311    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 23.3     |\n",
      "| steps                   | 20639    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 77       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 21.9     |\n",
      "| steps                   | 22827    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 26.2     |\n",
      "| steps                   | 25452    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 30.4     |\n",
      "| steps                   | 28489    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 28.9     |\n",
      "| steps                   | 31384    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 66       |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 28.1     |\n",
      "| steps                   | 34191    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 28.5     |\n",
      "| steps                   | 37042    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 19       |\n",
      "| steps                   | 38940    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 20.7     |\n",
      "| steps                   | 41008    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 27.1     |\n",
      "| steps                   | 43722    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 54       |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 27.2     |\n",
      "| steps                   | 46439    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 18       |\n",
      "| steps                   | 48235    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 22.4     |\n",
      "| steps                   | 50479    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 47       |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 26       |\n",
      "| steps                   | 53075    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 29       |\n",
      "| steps                   | 55977    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 42       |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 26.3     |\n",
      "| steps                   | 58609    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 39       |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 27.1     |\n",
      "| steps                   | 61320    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 37       |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 29.1     |\n",
      "| steps                   | 64229    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 30.4     |\n",
      "| steps                   | 67265    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 41.8     |\n",
      "| steps                   | 71440    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 25.6     |\n",
      "| steps                   | 73997    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 23       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 36.3     |\n",
      "| steps                   | 77630    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 46.4     |\n",
      "| steps                   | 82265    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 44.7     |\n",
      "| steps                   | 86738    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 53.4     |\n",
      "| steps                   | 92079    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 63.8     |\n",
      "| steps                   | 98459    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 79.5     |\n",
      "| steps                   | 106409   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 77.5     |\n",
      "| steps                   | 114158   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 79.8     |\n",
      "| steps                   | 122137   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 86.2     |\n",
      "| steps                   | 130755   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 92.7     |\n",
      "| steps                   | 140025   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 177      |\n",
      "| steps                   | 157685   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 28.2     |\n",
      "| steps                   | 160507   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 70.1     |\n",
      "| steps                   | 167513   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 48.8     |\n",
      "| steps                   | 172390   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 72.8     |\n",
      "| steps                   | 179674   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 88.7     |\n",
      "| steps                   | 188546   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 93.2     |\n",
      "| steps                   | 197866   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 90.8     |\n",
      "| steps                   | 206951   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 232      |\n",
      "| steps                   | 230143   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 320      |\n",
      "| steps                   | 262139   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 144      |\n",
      "| steps                   | 276555   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 117      |\n",
      "| steps                   | 288261   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 110      |\n",
      "| steps                   | 299236   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 99.7     |\n",
      "| steps                   | 309209   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 121      |\n",
      "| steps                   | 321345   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 148      |\n",
      "| steps                   | 336150   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 148      |\n",
      "| steps                   | 350953   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 350      |\n",
      "| steps                   | 385957   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 237      |\n",
      "| steps                   | 409655   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 132      |\n",
      "| steps                   | 422842   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 120      |\n",
      "| steps                   | 434835   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 160      |\n",
      "| steps                   | 450844   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 182      |\n",
      "| steps                   | 469035   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 270      |\n",
      "| steps                   | 495983   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 194      |\n",
      "| steps                   | 515356   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 142      |\n",
      "| steps                   | 529514   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 290      |\n",
      "| steps                   | 558518   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 191      |\n",
      "| steps                   | 577655   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 93.8     |\n",
      "| steps                   | 587035   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 132      |\n",
      "| steps                   | 600265   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 234      |\n",
      "| steps                   | 623625   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 216      |\n",
      "| steps                   | 645197   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7200     |\n",
      "| mean 100 episode reward | 149      |\n",
      "| steps                   | 660122   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7300     |\n",
      "| mean 100 episode reward | 147      |\n",
      "| steps                   | 674853   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7400     |\n",
      "| mean 100 episode reward | 99.2     |\n",
      "| steps                   | 684769   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7500     |\n",
      "| mean 100 episode reward | 247      |\n",
      "| steps                   | 709482   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7600     |\n",
      "| mean 100 episode reward | 112      |\n",
      "| steps                   | 720663   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7700     |\n",
      "| mean 100 episode reward | 278      |\n",
      "| steps                   | 748474   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7800     |\n",
      "| mean 100 episode reward | 380      |\n",
      "| steps                   | 786465   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7900     |\n",
      "| mean 100 episode reward | 171      |\n",
      "| steps                   | 803538   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 167      |\n",
      "| steps                   | 820276   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8100     |\n",
      "| mean 100 episode reward | 136      |\n",
      "| steps                   | 833895   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8200     |\n",
      "| mean 100 episode reward | 161      |\n",
      "| steps                   | 849964   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8300     |\n",
      "| mean 100 episode reward | 138      |\n",
      "| steps                   | 863815   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8400     |\n",
      "| mean 100 episode reward | 109      |\n",
      "| steps                   | 874721   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8500     |\n",
      "| mean 100 episode reward | 77       |\n",
      "| steps                   | 882420   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8600     |\n",
      "| mean 100 episode reward | 298      |\n",
      "| steps                   | 912195   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8700     |\n",
      "| mean 100 episode reward | 98       |\n",
      "| steps                   | 921995   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8800     |\n",
      "| mean 100 episode reward | 132      |\n",
      "| steps                   | 935231   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8900     |\n",
      "| mean 100 episode reward | 162      |\n",
      "| steps                   | 951471   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 298      |\n",
      "| steps                   | 981274   |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters\n",
    "dataset_name = 'expert_cartpole' # name of the dataset\n",
    "dataste_n_episodes = 1e4 # number of episodes in the dataset \n",
    "env_name = 'CartPole-v1' # name of the enviornment\n",
    "train_n_steps = 1e6 # number of tranings steps befor collecting data \n",
    "\n",
    "# Collect dataset\n",
    "model = DQN('MlpPolicy', env_name, verbose=1)\n",
    "generate_expert_traj(model, dataset_name, n_timesteps=int(train_n_steps), n_episodes=int(dataste_n_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
